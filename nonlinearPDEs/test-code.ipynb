{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8401e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manully compute derivative:  0.0016942024230957031\n",
      "autograd for derivative:  0.002557992935180664\n",
      "Manual Gradient 1 vs Autograd Gradient 1 Difference:\n",
      "tensor(2.5175e-14, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "\n",
      "Manual Gradient 2 vs Autograd Gradient 2 Difference:\n",
      "tensor(1.3284e-14, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "\n",
      "Manual Gradient 3 vs Autograd Gradient 3 Difference:\n",
      "tensor(1.5352e-14, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "\n",
      "Manual Laplacian vs Autograd Laplacian Difference:\n",
      "tensor(9.2570e-13, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np \n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "pi = torch.tensor(np.pi,dtype=torch.float64)\n",
    "ZERO = torch.tensor([0.]).to(device)\n",
    "\n",
    "# Constants\n",
    "freq = 2\n",
    "sigma = 0.15\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Gaussian function and its gradients\n",
    "def gaussian(x):\n",
    "    return torch.exp(-torch.sum((x - 0.5)**2, dim=1, keepdim=True) / (2 * sigma**2))\n",
    "\n",
    "def gaussian_grad_1(x):\n",
    "    return gaussian(x) * (-(x[:, 0:1] - 0.5) / (sigma**2))\n",
    "\n",
    "def gaussian_grad_2(x):\n",
    "    return gaussian(x) * (-(x[:, 1:2] - 0.5) / (sigma**2))\n",
    "\n",
    "def gaussian_grad_3(x):\n",
    "    return gaussian(x) * (-(x[:, 2:3] - 0.5) / (sigma**2))\n",
    "\n",
    "# Exact function u_exact\n",
    "def u_exact(x):\n",
    "    return gaussian(x) * torch.cos(2 * pi * freq * x[:, 0:1])\n",
    "\n",
    "# Manually computed gradients\n",
    "def u_grad_1(x):\n",
    "    return torch.cos(2 * pi * freq * x[:, 0:1]) * gaussian_grad_1(x) - 2 * pi * freq * torch.sin(2 * pi * freq * x[:, 0:1]) * gaussian(x)\n",
    "\n",
    "def u_grad_2(x):\n",
    "    return torch.cos(2 * pi * freq * x[:, 0:1]) * gaussian_grad_2(x)\n",
    "\n",
    "def u_grad_3(x):\n",
    "    return torch.cos(2 * pi * freq * x[:, 0:1]) * gaussian_grad_3(x)\n",
    "\n",
    "# Collecting the gradients in a list\n",
    "def u_exact_grad():\n",
    "    return [u_grad_1, u_grad_2, u_grad_3]\n",
    "\n",
    "# # Manually computed Laplacian\n",
    "def laplace_u_exact(x):\n",
    "    return - 2*pi*freq * torch.sin(2*pi*freq*x[:,0:1]) *gaussian_grad_1(x) \\\n",
    "            + torch.cos(2*pi*freq*x[:,0:1])*( gaussian(x) * ( ((x[:,0:1] - 0.5)/(sigma**2))**2 -1/(sigma**2))  ) \\\n",
    "            -( (2*pi*freq)**2 * torch.cos(2*pi*freq*x[:,0:1]) * gaussian(x) + (2*pi*freq)*torch.sin(2*pi*freq*x[:,0:1]) * gaussian_grad_1(x) ) \\\n",
    "            + torch.cos(2*pi*freq*x[:,0:1]) * (gaussian(x) * ( ((x[:,1:2] - 0.5)/(sigma**2))**2 -1/(sigma**2) )  ) \\\n",
    "            + torch.cos(2*pi*freq*x[:,0:1]) * ( gaussian(x) * ( ((x[:,2:3] - 0.5)/(sigma**2))**2 -1/(sigma**2) )   ) \\\n",
    "\n",
    "\n",
    "# def laplace_u_exact(x):\n",
    "#     # Second derivative w.r.t x_1\n",
    "#     term_1 = -(2 * pi * freq)**2 * torch.cos(2 * pi * freq * x[:, 0:1]) * gaussian(x)\n",
    "#     term_1 += torch.cos(2 * pi * freq * x[:, 0:1]) * gaussian(x) * ((x[:, 0:1] - 0.5)**2 / sigma**4 - 1 / sigma**2)\n",
    "#     term_1 += 2 * pi * freq * torch.sin(2 * pi * freq * x[:, 0:1]) * gaussian_grad_1(x)\n",
    "\n",
    "#     # Second derivative w.r.t x_2\n",
    "#     term_2 = torch.cos(2 * pi * freq * x[:, 0:1]) * gaussian(x) * ((x[:, 1:2] - 0.5)**2 / sigma**4 - 1 / sigma**2)\n",
    "\n",
    "#     # Second derivative w.r.t x_3\n",
    "#     term_3 = torch.cos(2 * pi * freq * x[:, 0:1]) * gaussian(x) * ((x[:, 2:3] - 0.5)**2 / sigma**4 - 1 / sigma**2)\n",
    "\n",
    "#     return term_1 + term_2 + term_3\n",
    "\n",
    "\n",
    "# Function to compute gradient using autograd\n",
    "def compute_autograd_grad(u_func, x):\n",
    "    x.requires_grad_(True)  # Enable gradient tracking for input x\n",
    "    u = u_func(x)\n",
    "    u_grad = torch.autograd.grad(outputs=u, inputs=x,\n",
    "                                 grad_outputs=torch.ones_like(u),\n",
    "                                 create_graph=True, retain_graph=True)[0]\n",
    "    return u_grad\n",
    "\n",
    "# Function to compute Laplacian using autograd\n",
    "def compute_autograd_laplace(u_func, x):\n",
    "    u_grad = compute_autograd_grad(u_func, x)\n",
    "    \n",
    "    laplacian = 0\n",
    "    for i in range(x.shape[1]):\n",
    "        grad_i = u_grad[:, i:i+1]\n",
    "        u_grad2_i = torch.autograd.grad(outputs=grad_i, inputs=x,\n",
    "                                        grad_outputs=torch.ones_like(grad_i),\n",
    "                                        create_graph=True, retain_graph=True)[0][:, i:i+1]\n",
    "        laplacian += u_grad2_i\n",
    "    return laplacian\n",
    "\n",
    "# Generate sample input points\n",
    "x = torch.rand(1000, 3).to(device)  # Random 3D points\n",
    "\n",
    "# Compute the manually computed gradients and Laplacian\n",
    "s_time = time.time()\n",
    "u_grad_manual_1 = u_grad_1(x)\n",
    "u_grad_manual_2 = u_grad_2(x)\n",
    "u_grad_manual_3 = u_grad_3(x)\n",
    "laplace_manual = laplace_u_exact(x)\n",
    "print(\"manully compute derivative: \",time.time() - s_time)\n",
    "\n",
    "# Compute the gradients and Laplacian using autograd\n",
    "s_time = time.time()\n",
    "u_grad_autograd = compute_autograd_grad(u_exact, x)\n",
    "laplace_autograd = compute_autograd_laplace(u_exact, x)\n",
    "print(\"autograd for derivative: \",time.time() - s_time)\n",
    "# Compute differences for comparison\n",
    "grad_diff_1 = torch.abs(u_grad_manual_1 - u_grad_autograd[:, 0:1])\n",
    "grad_diff_2 = torch.abs(u_grad_manual_2 - u_grad_autograd[:, 1:2])\n",
    "grad_diff_3 = torch.abs(u_grad_manual_3 - u_grad_autograd[:, 2:3])\n",
    "laplace_diff = torch.abs(laplace_manual - laplace_autograd)\n",
    "\n",
    "# Display the results\n",
    "print(\"Manual Gradient 1 vs Autograd Gradient 1 Difference:\")\n",
    "print(grad_diff_1.sum())\n",
    "\n",
    "print(\"\\nManual Gradient 2 vs Autograd Gradient 2 Difference:\")\n",
    "print(grad_diff_2.sum())\n",
    "\n",
    "print(\"\\nManual Gradient 3 vs Autograd Gradient 3 Difference:\")\n",
    "print(grad_diff_3.sum())\n",
    "\n",
    "print(\"\\nManual Laplacian vs Autograd Laplacian Difference:\")\n",
    "print(laplace_diff.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ebae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
