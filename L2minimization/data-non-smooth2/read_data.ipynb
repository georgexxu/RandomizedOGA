{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "import os \n",
    "from scipy.sparse import linalg\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda\" \n",
    "else:  \n",
    "    device = \"cpu\"    \n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "pi = torch.tensor(np.pi)\n",
    "ZERO = torch.tensor([0.]).to(device)\n",
    "torch.set_printoptions(precision=6)\n",
    "\n",
    "class model(nn.Module):\n",
    "    \"\"\" ReLU k shallow neural network\n",
    "    Parameters: \n",
    "    input size: input dimension\n",
    "    hidden_size1 : number of hidden layers \n",
    "    num_classes: output classes \n",
    "    k: degree of relu functions\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size1, num_classes,k = 1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, num_classes,bias = False)\n",
    "        self.k = k \n",
    "    def forward(self, x):\n",
    "        u1 = self.fc2(F.relu(self.fc1(x))**self.k)\n",
    "        return u1\n",
    "    def evaluate_derivative(self, x, i):\n",
    "        if self.k == 1:\n",
    "            u1 = self.fc2(torch.heaviside(self.fc1(x),ZERO) * self.fc1.weight.t()[i-1:i,:] )\n",
    "        else:\n",
    "            u1 = self.fc2(self.k*F.relu(self.fc1(x))**(self.k-1) *self.fc1.weight.t()[i-1:i,:] )  \n",
    "        return u1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_convergence_order(err_l2,exponent,dict_size,k,d, filename,write2file = False):\n",
    "    \n",
    "    if write2file:\n",
    "        file_mode = \"a\" if os.path.exists(filename) else \"w\"\n",
    "        f_write = open(filename, file_mode)\n",
    "    \n",
    "    neuron_nums = [2**j for j in range(2,exponent+1)]\n",
    "    err_list = [err_l2[i] for i in neuron_nums ]\n",
    "    l2_order = -1/2-(2*k + 1)/(2*d)\n",
    "    if write2file:\n",
    "        f_write.write('dictionary size: {}\\n'.format(dict_size))\n",
    "        f_write.write(\"neuron num \\t\\t error \\t\\t order{} \\t\\t h10 error \\\\ order \\n\".format(l2_order))\n",
    "    print(\"neuron num \\t\\t error \\t\\t order\")\n",
    "    for i, item in enumerate(err_list):\n",
    "        if i == 0: \n",
    "            print(\"{} \\t\\t {:.6f} \\t\\t *  \\n\".format(neuron_nums[i],item ) )\n",
    "            if write2file: \n",
    "                f_write.write(\"{} \\t\\t {} \\t\\t * \\t\\t \\n\".format(neuron_nums[i],item ))\n",
    "        else: \n",
    "            print(\"{} \\t\\t {:.6f} \\t\\t {:.6f} \\n\".format(neuron_nums[i],item,np.log(err_list[i-1]/err_list[i])/np.log(2) ) )\n",
    "            if write2file: \n",
    "                f_write.write(\"{} \\t\\t {} \\t\\t {} \\n\".format(neuron_nums[i],item,np.log(err_list[i-1]/err_list[i])/np.log(2) ))\n",
    "    if write2file:     \n",
    "        f_write.write(\"\\n\")\n",
    "        f_write.close()\n",
    "\n",
    "\n",
    "def show_convergence_order_latex(err_l2,exponent,k=1,d=1): \n",
    "    neuron_nums = [2**j for j in range(2,exponent+1)]\n",
    "    err_list = [err_l2[i] for i in neuron_nums ]\n",
    "    l2_order = -1/2-(2*k + 1)/(2*d)\n",
    "    print(\"neuron num  & \\t $\\\\|u-u_n \\\\|_{{L^2}}$ & \\t order $O(n^{{{:.2f}}})$  \\\\\\\\ \\\\hline \\\\hline \".format(l2_order))\n",
    "    for i, item in enumerate(err_list):\n",
    "        if i == 0: \n",
    "            print(\"{} \\t\\t & {:.6f} &\\t\\t *  \\\\\\ \\hline  \\n\".format(neuron_nums[i],item) )   \n",
    "        else: \n",
    "            print(\"{} \\t\\t &  {:.2e} &  \\t\\t {:.2f} \\\\\\ \\hline  \\n\".format(neuron_nums[i],item,np.log(err_list[i-1]/err_list[i])/np.log(2) ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D interface example   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D $u(x_1,x_2) = \\sqrt{x_1^2 + x_2^2}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relu_k = 1\n",
      "neuron num  & \t $\\|u-u_n \\|_{L^2}$ & \t order $O(n^{-1.25})$  \\\\ \\hline \\hline \n",
      "4 \t\t & 0.362867 &\t\t *  \\\\ \\hline  \n",
      "\n",
      "8 \t\t &  3.80e-02 &  \t\t 3.26 \\\\ \\hline  \n",
      "\n",
      "16 \t\t &  1.47e-02 &  \t\t 1.36 \\\\ \\hline  \n",
      "\n",
      "32 \t\t &  5.72e-03 &  \t\t 1.37 \\\\ \\hline  \n",
      "\n",
      "64 \t\t &  1.94e-03 &  \t\t 1.56 \\\\ \\hline  \n",
      "\n",
      "128 \t\t &  6.78e-04 &  \t\t 1.51 \\\\ \\hline  \n",
      "\n",
      "256 \t\t &  2.28e-04 &  \t\t 1.57 \\\\ \\hline  \n",
      "\n",
      "512 \t\t &  6.51e-05 &  \t\t 1.80 \\\\ \\hline  \n",
      "\n",
      "1024 \t\t &  2.10e-05 &  \t\t 1.64 \\\\ \\hline  \n",
      "\n",
      "relu_k = 2\n",
      "neuron num  & \t $\\|u-u_n \\|_{L^2}$ & \t order $O(n^{-1.75})$  \\\\ \\hline \\hline \n",
      "4 \t\t & 0.357457 &\t\t *  \\\\ \\hline  \n",
      "\n",
      "8 \t\t &  9.22e-02 &  \t\t 1.96 \\\\ \\hline  \n",
      "\n",
      "16 \t\t &  2.77e-02 &  \t\t 1.73 \\\\ \\hline  \n",
      "\n",
      "32 \t\t &  9.34e-03 &  \t\t 1.57 \\\\ \\hline  \n",
      "\n",
      "64 \t\t &  3.51e-03 &  \t\t 1.41 \\\\ \\hline  \n",
      "\n",
      "128 \t\t &  1.42e-03 &  \t\t 1.31 \\\\ \\hline  \n",
      "\n",
      "256 \t\t &  5.39e-04 &  \t\t 1.39 \\\\ \\hline  \n",
      "\n",
      "512 \t\t &  2.01e-04 &  \t\t 1.42 \\\\ \\hline  \n",
      "\n",
      "1024 \t\t &  7.83e-05 &  \t\t 1.36 \\\\ \\hline  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#N = 4096 \n",
    "dim =2  \n",
    "function_name = \"cone2d\"\n",
    "for relu_k in [1,2]:  \n",
    "    print(\"relu_k = {}\".format(relu_k)) \n",
    "    trial_num = 5 \n",
    "    errl2_trials = [] \n",
    "    for N0 in [2**12]: \n",
    "        s = 1 \n",
    "        for trial in range(trial_num):\n",
    "            exponent = 10\n",
    "            num_epochs = 2**exponent  \n",
    "            folder = './' \n",
    "            filename = folder + 'err_OGA_2D_{}_relu{}_neuron_{}_N_{}_randomized_trial{}.pt'.format(function_name,relu_k,num_epochs,s*N0,trial)\n",
    "            errl2 = torch.load(filename)\n",
    "            errl2_trials.append(errl2)\n",
    "    errl2_trials = torch.stack(errl2_trials, dim = 0)\n",
    "    errl2_ave = errl2_trials.mean(dim = 0)\n",
    "    errl2_var = errl2_trials.var(dim = 0)\n",
    "\n",
    "    show_convergence_order_latex(errl2_ave,exponent, k=relu_k, d=dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D $L^2$ shaped example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
